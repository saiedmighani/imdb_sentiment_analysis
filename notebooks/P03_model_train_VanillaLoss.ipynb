{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Sentiment Analysis with Custom Loss Function<br>\n",
    "#### Part 3. Model train using vanilla loss function<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.dataset import IMDBDataset\n",
    "from src.model import SentimentClassifier\n",
    "from src.loss import VanillaBCELoss, ClassifierMetrics\n",
    "from src.utils import set_seed\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "set_seed(101)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load imdb datasets\n",
    "raw_datasets = load_dataset(\"imdb\")\n",
    "\n",
    "\n",
    "# Split original imdb train/test into train/val/test\n",
    "full_train_dataset = IMDBDataset(raw_datasets[\"train\"])\n",
    "test_dataset = IMDBDataset(raw_datasets[\"test\"])\n",
    "\n",
    "train_size = int(0.8 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 20000\n",
      "Validation dataset size: 5000\n",
      "Test dataset size: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and loss function build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentClassifier().to(device)\n",
    "loss_fn = VanillaBCELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "metrics = ClassifierMetrics(threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checkpoint dir and last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"checkpoints_vanilla\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "resume_path = os.path.join(checkpoint_dir, \"last_checkpoint.pt\")\n",
    "metrics_csv = os.path.join(checkpoint_dir, \"metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses = [], []\n",
    "train_f1_scores, val_f1_scores = [], []\n",
    "train_precisions, val_precisions = [], []\n",
    "train_recalls, val_recalls = [], []\n",
    "best_val_f1 = 0.0\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial checkpoint load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(resume_path):\n",
    "    print(\"Resuming from checkpoint: {}\".format(resume_path))\n",
    "    checkpoint = torch.load(resume_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    train_losses = checkpoint['train_losses']\n",
    "    val_losses = checkpoint['val_losses']\n",
    "    train_f1_scores = checkpoint['train_f1_scores']\n",
    "    val_f1_scores = checkpoint['val_f1_scores']\n",
    "    train_precisions = checkpoint.get('train_precisions', [])\n",
    "    train_recalls = checkpoint.get('train_recalls', [])\n",
    "    val_precisions = checkpoint.get('val_precisions', [])\n",
    "    val_recalls = checkpoint.get('val_recalls', [])\n",
    "    best_val_f1 = checkpoint['best_val_f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up logging file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(metrics_csv):\n",
    "    with open(metrics_csv, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"epoch\",\n",
    "            \"train_loss\", \"train_precision\", \"train_recall\", \"train_f1\",\n",
    "            \"val_loss\", \"val_precision\", \"val_recall\", \"val_f1\"\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2548/3748590709.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  lengths = torch.tensor(batch['length'], dtype=torch.float32).to(device)\n",
      "/tmp/ipykernel_2548/3748590709.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  lengths = torch.tensor(batch['length'], dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "total_epoch = 3\n",
    "\n",
    "for epoch in range(start_epoch, total_epoch):\n",
    "    print(\"Epoch {}\\n\".format(epoch + 1))\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    train_preds, train_labels = [], []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        lengths = torch.tensor(batch['length'], dtype=torch.float32).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(outputs, labels, lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        train_preds.extend(torch.sigmoid(outputs).detach().cpu().numpy())\n",
    "        train_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_metrics = metrics.compute(train_labels, train_preds)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_f1_scores.append(train_metrics[\"f1\"])\n",
    "    train_precisions.append(train_metrics[\"precision\"])\n",
    "    train_recalls.append(train_metrics[\"recall\"])\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            lengths = torch.tensor(batch['length'], dtype=torch.float32).to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = loss_fn(outputs, labels, lengths)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            val_preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_metrics = metrics.compute(val_labels, val_preds)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_f1_scores.append(val_metrics[\"f1\"])\n",
    "    val_precisions.append(val_metrics[\"precision\"])\n",
    "    val_recalls.append(val_metrics[\"recall\"])\n",
    "\n",
    "    print(\"Train loss: {:.4f} | Precision: {:.4f} | Recall: {:.4f} | F1: {:.4f}\".format(\n",
    "    avg_train_loss,\n",
    "    train_metrics['precision'],\n",
    "    train_metrics['recall'],\n",
    "    train_metrics['f1']))\n",
    "\n",
    "    print(\"Val   loss: {:.4f} | Precision: {:.4f} | Recall: {:.4f} | F1: {:.4f}\".format(\n",
    "        avg_val_loss,\n",
    "        val_metrics['precision'],\n",
    "        val_metrics['recall'],\n",
    "        val_metrics['f1']))\n",
    "    \n",
    "    print(\"Epoch time: {:.2f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "    # Save to CSV\n",
    "    with open(metrics_csv, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            epoch + 1,\n",
    "            avg_train_loss, train_metrics[\"precision\"], train_metrics[\"recall\"], train_metrics[\"f1\"],\n",
    "            avg_val_loss, val_metrics[\"precision\"], val_metrics[\"recall\"], val_metrics[\"f1\"]\n",
    "        ])\n",
    "\n",
    "    # Save checkpoint\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_f1_scores': train_f1_scores,\n",
    "        'val_f1_scores': val_f1_scores,\n",
    "        'train_precisions': train_precisions,\n",
    "        'train_recalls': train_recalls,\n",
    "        'val_precisions': val_precisions,\n",
    "        'val_recalls': val_recalls,\n",
    "        'best_val_f1': best_val_f1\n",
    "    }, resume_path)\n",
    "    print(f\"Saved checkpoint: {resume_path}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_metrics[\"f1\"] > best_val_f1:\n",
    "        best_val_f1 = val_metrics[\"f1\"]\n",
    "        torch.save(model.state_dict(), os.path.join(checkpoint_dir, \"best_model.pt\"))\n",
    "        print(\"Best model updated!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_preds, test_labels = [], []\n",
    "total_test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        lengths = torch.tensor(batch['length'], dtype=torch.float32).to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(outputs, labels, lengths)\n",
    "        total_test_loss += loss.item()\n",
    "\n",
    "        test_preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "test_metrics = metrics.compute(test_labels, test_preds)\n",
    "\n",
    "# Print final test results\n",
    "print(\"Final Test Loss: {:.4f}\".format(avg_test_loss))\n",
    "print(\"Final Test Precision: {:.4f} | Recall: {:.4f} | F1: {:.4f}\".format(\n",
    "    test_metrics[\"precision\"],\n",
    "    test_metrics[\"recall\"],\n",
    "    test_metrics[\"f1\"]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = list(range(1, len(train_losses) + 1))\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
    "plt.axhline(y=avg_test_loss, color=\"r\", linestyle=\"--\", label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs, train_f1_scores, label=\"Train F1\")\n",
    "plt.plot(epochs, val_f1_scores, label=\"Val F1\")\n",
    "plt.axhline(y=test_metrics['f1'], color=\"r\", linestyle=\"--\", label=\"Test F1\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"F1 Score Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs, train_precisions, label=\"Train Precision\")\n",
    "plt.plot(epochs, val_precisions, label=\"Val Precision\")\n",
    "plt.axhline(y=test_metrics['precision'], color=\"r\", linestyle=\"--\", label=\"Test Precision\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs, train_recalls, label=\"Train Recall\")\n",
    "plt.plot(epochs, val_recalls, label=\"Val Recall\")\n",
    "plt.axhline(y=test_metrics['recall'], color=\"r\", linestyle=\"--\", label=\"Test Recall\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.title(\"Recall Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"assets/metrics_vanilla_loss.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
